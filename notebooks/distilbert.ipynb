{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12751789,"sourceType":"datasetVersion","datasetId":8061096}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-13T10:08:26.308733Z","iopub.execute_input":"2025-08-13T10:08:26.309032Z","iopub.status.idle":"2025-08-13T10:08:26.759790Z","shell.execute_reply.started":"2025-08-13T10:08:26.309009Z","shell.execute_reply":"2025-08-13T10:08:26.758964Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/multi-domain-dataset/politifact_real.csv\n/kaggle/input/multi-domain-dataset/politifact_fake.csv\n/kaggle/input/multi-domain-dataset/gossipcop_real.csv\n/kaggle/input/multi-domain-dataset/gossipcop_fake.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\nos.environ[\"WANDB_MODE\"] = \"disabled\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T10:08:26.760831Z","iopub.execute_input":"2025-08-13T10:08:26.761172Z","iopub.status.idle":"2025-08-13T10:08:26.764960Z","shell.execute_reply.started":"2025-08-13T10:08:26.761110Z","shell.execute_reply":"2025-08-13T10:08:26.764051Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T10:08:26.892847Z","iopub.execute_input":"2025-08-13T10:08:26.893281Z","iopub.status.idle":"2025-08-13T10:08:26.896998Z","shell.execute_reply.started":"2025-08-13T10:08:26.893262Z","shell.execute_reply":"2025-08-13T10:08:26.896415Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!pip uninstall -y wandb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T10:08:27.828423Z","iopub.execute_input":"2025-08-13T10:08:27.828710Z","iopub.status.idle":"2025-08-13T10:08:28.542218Z","shell.execute_reply.started":"2025-08-13T10:08:27.828688Z","shell.execute_reply":"2025-08-13T10:08:28.541454Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Skipping wandb as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!pip install --upgrade pip\n!pip install virtualenv\n!virtualenv kaggle_env\n!source kaggle_env/bin/activate\n!pip install torch==2.3.1 datasets==2.21.0 accelerate==0.33.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T06:29:37.726074Z","iopub.execute_input":"2025-08-13T06:29:37.726416Z","iopub.status.idle":"2025-08-13T06:29:44.469141Z","shell.execute_reply.started":"2025-08-13T06:29:37.726394Z","shell.execute_reply":"2025-08-13T06:29:44.468173Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.2)\nRequirement already satisfied: virtualenv in /usr/local/lib/python3.11/dist-packages (20.33.1)\nRequirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from virtualenv) (0.4.0)\nRequirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.11/dist-packages (from virtualenv) (3.18.0)\nRequirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from virtualenv) (4.3.8)\ncreated virtual environment CPython3.11.13.final.0-64 in 289ms\n  creator CPython3Posix(dest=/kaggle/working/kaggle_env, clear=False, no_vcs_ignore=False, global=False)\n  seeder FromAppData(download=False, pip=bundle, setuptools=bundle, via=copy, app_data_dir=/root/.local/share/virtualenv)\n    added seed packages: pip==25.1.1, setuptools==80.9.0\n  activators BashActivator,CShellActivator,FishActivator,NushellActivator,PowerShellActivator,PythonActivator\nRequirement already satisfied: torch==2.3.1 in /usr/local/lib/python3.11/dist-packages (2.3.1)\nRequirement already satisfied: datasets==2.21.0 in /usr/local/lib/python3.11/dist-packages (2.21.0)\nRequirement already satisfied: accelerate==0.33.0 in /usr/local/lib/python3.11/dist-packages (0.33.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (4.14.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (2024.6.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (2.20.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (12.1.105)\nRequirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.1) (2.3.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (2.32.4)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (0.70.16)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (3.12.13)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (0.33.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (6.0.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==0.33.0) (7.0.0)\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from accelerate==0.33.0) (0.5.3)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1) (12.5.82)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets==2.21.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets==2.21.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets==2.21.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets==2.21.0) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets==2.21.0) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets==2.21.0) (2.4.1)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.21.0) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.21.0) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.21.0) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.21.0) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.21.0) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.21.0) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.21.0) (1.20.1)\nRequirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets==2.21.0) (3.10)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.2->datasets==2.21.0) (1.1.5)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.21.0) (3.4.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.21.0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.21.0) (2025.6.15)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.3.1) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets==2.21.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets==2.21.0) (2022.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets==2.21.0) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets==2.21.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets==2.21.0) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.21.0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.21.0) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.21.0) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.21.0) (1.17.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.3.1) (1.3.0)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Uninstall the broken packages\n!pip uninstall -y transformers\n!pip uninstall -y tokenizers\n\n# Remove leftover corrupted directories\n!rm -rf /usr/local/lib/python3.11/dist-packages/~ransformers*\n!rm -rf /usr/local/lib/python3.11/dist-packages/transformers*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T06:29:44.470268Z","iopub.execute_input":"2025-08-13T06:29:44.470556Z","iopub.status.idle":"2025-08-13T06:29:46.434323Z","shell.execute_reply.started":"2025-08-13T06:29:44.470520Z","shell.execute_reply":"2025-08-13T06:29:46.433301Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: transformers 4.44.2\nUninstalling transformers-4.44.2:\n  Successfully uninstalled transformers-4.44.2\nFound existing installation: tokenizers 0.19.1\nUninstalling tokenizers-0.19.1:\n  Successfully uninstalled tokenizers-0.19.1\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!pip install transformers==4.44.2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T06:29:46.435430Z","iopub.execute_input":"2025-08-13T06:29:46.435700Z","iopub.status.idle":"2025-08-13T06:29:54.691385Z","shell.execute_reply.started":"2025-08-13T06:29:46.435677Z","shell.execute_reply":"2025-08-13T06:29:54.690679Z"}},"outputs":[{"name":"stdout","text":"Collecting transformers==4.44.2\n  Using cached transformers-4.44.2-py3-none-any.whl.metadata (43 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (0.33.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (2.32.4)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (0.5.3)\nCollecting tokenizers<0.20,>=0.19 (from transformers==4.44.2)\n  Using cached tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.44.2) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.44.2) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.44.2) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.44.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.44.2) (2022.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.44.2) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.44.2) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.44.2) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.44.2) (2025.6.15)\nUsing cached transformers-4.44.2-py3-none-any.whl (9.5 MB)\nUsing cached tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\nInstalling collected packages: tokenizers, transformers\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [transformers][0m [transformers]\n\u001b[1A\u001b[2KSuccessfully installed tokenizers-0.19.1 transformers-4.44.2\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from transformers import Trainer,TrainingArguments\nprint(\"Transformers working fine!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T06:29:54.692534Z","iopub.execute_input":"2025-08-13T06:29:54.692838Z","iopub.status.idle":"2025-08-13T06:29:58.030819Z","shell.execute_reply.started":"2025-08-13T06:29:54.692804Z","shell.execute_reply":"2025-08-13T06:29:58.030139Z"}},"outputs":[{"name":"stdout","text":"Transformers working fine!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!pip install protobuf==3.20.3 --force-reinstall","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T06:29:58.031541Z","iopub.execute_input":"2025-08-13T06:29:58.031982Z","iopub.status.idle":"2025-08-13T06:30:01.560615Z","shell.execute_reply.started":"2025-08-13T06:29:58.031960Z","shell.execute_reply":"2025-08-13T06:30:01.559866Z"}},"outputs":[{"name":"stdout","text":"Collecting protobuf==3.20.3\n  Using cached protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\nUsing cached protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\nInstalling collected packages: protobuf\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, which is not installed.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\ndataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed protobuf-3.20.3\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!pip uninstall -y onnx tensorflow-metadata grpcio-status google-cloud-automl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T06:30:01.561793Z","iopub.execute_input":"2025-08-13T06:30:01.562146Z","iopub.status.idle":"2025-08-13T06:30:02.303086Z","shell.execute_reply.started":"2025-08-13T06:30:01.562086Z","shell.execute_reply":"2025-08-13T06:30:02.302323Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Skipping onnx as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping tensorflow-metadata as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping grpcio-status as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping google-cloud-automl as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!pip uninstall -y tensorflow-datasets tensorflow tensorflow-metadata onnx grpcio-status google-cloud-automl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T06:30:02.305447Z","iopub.execute_input":"2025-08-13T06:30:02.305734Z","iopub.status.idle":"2025-08-13T06:30:03.084188Z","shell.execute_reply.started":"2025-08-13T06:30:02.305701Z","shell.execute_reply":"2025-08-13T06:30:03.083403Z"}},"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Skipping tensorflow-datasets as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping tensorflow-metadata as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping onnx as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping grpcio-status as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping google-cloud-automl as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import os,re,math\nimport random\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nimport torch\nimport torch.nn as nn\nfrom transformers import Trainer,AutoTokenizer,AutoModelForSequenceClassification,TrainingArguments,EarlyStoppingCallback","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T10:08:44.218369Z","iopub.execute_input":"2025-08-13T10:08:44.218640Z","iopub.status.idle":"2025-08-13T10:08:47.822234Z","shell.execute_reply.started":"2025-08-13T10:08:44.218619Z","shell.execute_reply":"2025-08-13T10:08:47.821453Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"SEED = 42\nrandom.seed(SEED); np.random.seed(SEED)\ntorch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T10:08:49.828027Z","iopub.execute_input":"2025-08-13T10:08:49.828554Z","iopub.status.idle":"2025-08-13T10:08:49.835564Z","shell.execute_reply.started":"2025-08-13T10:08:49.828527Z","shell.execute_reply":"2025-08-13T10:08:49.834798Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"true_politifact= \"/kaggle/input/multi-domain-dataset/politifact_real.csv\"\nfake_politifact= \"/kaggle/input/multi-domain-dataset/politifact_fake.csv\"\ntrue_gossipcop=\"/kaggle/input/multi-domain-dataset/gossipcop_real.csv\"\nfake_gossipcop=\"/kaggle/input/multi-domain-dataset/gossipcop_fake.csv\"\n\n\n# dataset 1\ntrue_path_politifact=pd.read_csv(true_politifact)\nfake_path_politifact=pd.read_csv(fake_politifact)\n\ntrue_path_politifact[\"label\"]=1\nfake_path_politifact[\"label\"]=0\n\nPOLITIFACT_CSV= pd.concat([true_path_politifact, fake_path_politifact], ignore_index=True)\n\nPOLITIFACT_CSV.head()\n\n\n\n#dataset 2\ntrue_path_gossipcop=pd.read_csv(true_gossipcop)\nfake_path_gossipcop=pd.read_csv(fake_gossipcop)\n\ntrue_path_gossipcop[\"label\"]=1\nfake_path_gossipcop[\"label\"]=0\n\nGOSSIPCOP_CSV= pd.concat([true_path_gossipcop, fake_path_gossipcop], ignore_index=True)\n\nGOSSIPCOP_CSV.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T10:08:51.193870Z","iopub.execute_input":"2025-08-13T10:08:51.194150Z","iopub.status.idle":"2025-08-13T10:08:51.828575Z","shell.execute_reply.started":"2025-08-13T10:08:51.194132Z","shell.execute_reply":"2025-08-13T10:08:51.827873Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                 id                                           news_url  \\\n0  gossipcop-882573  https://www.brides.com/story/teen-mom-jenelle-...   \n1  gossipcop-875924  https://www.dailymail.co.uk/tvshowbiz/article-...   \n2  gossipcop-894416        https://en.wikipedia.org/wiki/Quinn_Perkins   \n3  gossipcop-857248  https://www.refinery29.com/en-us/2018/03/19192...   \n4  gossipcop-884684  https://www.cnn.com/2017/10/04/entertainment/c...   \n\n                                               title  \\\n0  Teen Mom Star Jenelle Evans' Wedding Dress Is ...   \n1  Kylie Jenner refusing to discuss Tyga on Life ...   \n2                                      Quinn Perkins   \n3  I Tried Kim Kardashian's Butt Workout & Am For...   \n4  Celine Dion donates concert proceeds to Vegas ...   \n\n                                           tweet_ids  label  \n0  912371411146149888\\t912371528343408641\\t912372...      1  \n1  901989917546426369\\t901989992074969089\\t901990...      1  \n2  931263637246881792\\t931265332022579201\\t931265...      1  \n3  868114761723936769\\t868122567910936576\\t868128...      1  \n4  915528047004209152\\t915529285171122176\\t915530...      1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>news_url</th>\n      <th>title</th>\n      <th>tweet_ids</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>gossipcop-882573</td>\n      <td>https://www.brides.com/story/teen-mom-jenelle-...</td>\n      <td>Teen Mom Star Jenelle Evans' Wedding Dress Is ...</td>\n      <td>912371411146149888\\t912371528343408641\\t912372...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>gossipcop-875924</td>\n      <td>https://www.dailymail.co.uk/tvshowbiz/article-...</td>\n      <td>Kylie Jenner refusing to discuss Tyga on Life ...</td>\n      <td>901989917546426369\\t901989992074969089\\t901990...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>gossipcop-894416</td>\n      <td>https://en.wikipedia.org/wiki/Quinn_Perkins</td>\n      <td>Quinn Perkins</td>\n      <td>931263637246881792\\t931265332022579201\\t931265...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>gossipcop-857248</td>\n      <td>https://www.refinery29.com/en-us/2018/03/19192...</td>\n      <td>I Tried Kim Kardashian's Butt Workout &amp; Am For...</td>\n      <td>868114761723936769\\t868122567910936576\\t868128...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>gossipcop-884684</td>\n      <td>https://www.cnn.com/2017/10/04/entertainment/c...</td>\n      <td>Celine Dion donates concert proceeds to Vegas ...</td>\n      <td>915528047004209152\\t915529285171122176\\t915530...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"PROCESSED_DIR = \"/kaggle/working/processed_datasets\"\nos.makedirs(PROCESSED_DIR, exist_ok=True)\n\npolitifact_path = os.path.join(PROCESSED_DIR, \"politifact.csv\")\nPOLITIFACT_CSV.to_csv(politifact_path, index=False)\n\ngossipcop_path = os.path.join(PROCESSED_DIR, \"gossipcop.csv\")\nGOSSIPCOP_CSV.to_csv(gossipcop_path, index=False)\n\nPOLITIFACT_CSV=\"/kaggle/working/processed_datasets/politifact.csv\"\nGOSSIPCOP_CSV=\"/kaggle/working/processed_datasets/gossipcop.csv\"","metadata":{"execution":{"iopub.status.busy":"2025-08-13T10:08:55.609542Z","iopub.execute_input":"2025-08-13T10:08:55.609822Z","iopub.status.idle":"2025-08-13T10:08:56.865130Z","shell.execute_reply.started":"2025-08-13T10:08:55.609802Z","shell.execute_reply":"2025-08-13T10:08:56.864110Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"MODEL_NAME = \"distilbert-base-uncased\"\nMAX_LEN = 128            # titles: 64–128 is enough; smaller helps generalization\nEPOCHS = 8               # early stopping will stop earlier\nBATCH_TRAIN = 32         # increase/decrease based on GPU RAM\nBATCH_EVAL  = 64\nLR = 2e-5\nWEIGHT_DECAY = 0.1\nWARMUP_RATIO = 0.06\nDROPOUT = 0.3            # stronger than default to reduce overfit\nATTN_DROPOUT = 0.3\nVAL_FRAC = 0.1           # validation split from the training domain\nTEST_FRAC = 0.2  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T10:09:06.668844Z","iopub.execute_input":"2025-08-13T10:09:06.669367Z","iopub.status.idle":"2025-08-13T10:09:06.674062Z","shell.execute_reply.started":"2025-08-13T10:09:06.669341Z","shell.execute_reply":"2025-08-13T10:09:06.673045Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"OUTPUT_DIR = \"/kaggle/working/domain_transfer_distilbert\"\n\nos.makedirs(OUTPUT_DIR, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T10:09:09.188674Z","iopub.execute_input":"2025-08-13T10:09:09.188952Z","iopub.status.idle":"2025-08-13T10:09:09.192823Z","shell.execute_reply.started":"2025-08-13T10:09:09.188930Z","shell.execute_reply":"2025-08-13T10:09:09.192008Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def clean_title(s: str) -> str:\n    s = str(s)\n    s = re.sub(r\"http\\S+|www\\.\\S+\", \" \", s)\n    s = re.sub(r\"\\s+\", \" \", s).strip()\n    return s","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T10:09:10.523087Z","iopub.execute_input":"2025-08-13T10:09:10.523804Z","iopub.status.idle":"2025-08-13T10:09:10.527468Z","shell.execute_reply.started":"2025-08-13T10:09:10.523779Z","shell.execute_reply":"2025-08-13T10:09:10.526785Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def load_domain(path: str, domain_name: str) -> pd.DataFrame:\n    \"\"\"Load a domain CSV with columns ['title','label'].\n       Returns cleaned, deduped DataFrame with ['title','label','domain'].\n    \"\"\"\n    df = pd.read_csv(path)\n    # Normalize column names if needed (uncomment if your CSV uses different names)\n    # df = df.rename(columns={\"headline\": \"title\", \"verdict\": \"label\"})\n    df = df[[\"title\", \"label\"]].copy()\n    df[\"title\"] = df[\"title\"].fillna(\"\").map(clean_title)\n    df = df[df[\"title\"].str.len() > 3]  # drop empty/very short\n    df[\"label\"] = df[\"label\"].astype(int)\n    df[\"domain\"] = domain_name\n    df = df.drop_duplicates(subset=[\"title\"]).reset_index(drop=True)\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T10:09:11.702842Z","iopub.execute_input":"2025-08-13T10:09:11.703616Z","iopub.status.idle":"2025-08-13T10:09:11.708391Z","shell.execute_reply.started":"2025-08-13T10:09:11.703590Z","shell.execute_reply":"2025-08-13T10:09:11.707763Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"from datasets import Dataset\n\ndef to_hf_dataset(df: pd.DataFrame, tok, max_len: int) -> Dataset:\n    ds = Dataset.from_pandas(df[[\"title\", \"label\"]].reset_index(drop=True))\n    def tok_fn(batch):\n        return tok(batch[\"title\"], padding=\"max_length\", truncation=True, max_length=max_len)\n    ds = ds.map(tok_fn, batched=True, desc=\"Tokenizing\")\n    ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n    return ds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T10:09:30.338304Z","iopub.execute_input":"2025-08-13T10:09:30.338609Z","iopub.status.idle":"2025-08-13T10:09:30.343929Z","shell.execute_reply.started":"2025-08-13T10:09:30.338571Z","shell.execute_reply":"2025-08-13T10:09:30.343041Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score\n\ndef metrics_fn(eval_pred):\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis=-1)\n    return {\n        \"accuracy\": accuracy_score(labels, preds),\n        \"f1\": f1_score(labels, preds, zero_division=0),\n        \"precision\": precision_score(labels, preds, zero_division=0),\n        \"recall\": recall_score(labels, preds, zero_division=0),\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T10:12:29.243054Z","iopub.execute_input":"2025-08-13T10:12:29.243648Z","iopub.status.idle":"2025-08-13T10:12:29.248841Z","shell.execute_reply.started":"2025-08-13T10:12:29.243617Z","shell.execute_reply":"2025-08-13T10:12:29.247964Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"class WeightedCELossTrainer(Trainer):\n    \"\"\"Inject class weights into CE loss.\"\"\"\n    def __init__(self, class_weights=None, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.class_weights = class_weights\n        self.loss_fct = None\n\n    def compute_loss(self, model, inputs, return_outputs=False):\n        if self.loss_fct is None:\n            if self.class_weights is not None:\n                device = next(model.parameters()).device  \n                cw = self.class_weights.to(device)\n                self.loss_fct = nn.CrossEntropyLoss(weight=cw)\n            else:\n                self.loss_fct = nn.CrossEntropyLoss()\n\n        labels = inputs.get(\"labels\")\n        outputs = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], labels=None)\n        logits = outputs.logits\n        loss = self.loss_fct(logits.view(-1, getattr(model, \"module\", model).config.num_labels\n), labels.view(-1))\n        return (loss, outputs) if return_outputs else loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T10:09:33.167679Z","iopub.execute_input":"2025-08-13T10:09:33.167962Z","iopub.status.idle":"2025-08-13T10:09:33.174002Z","shell.execute_reply.started":"2025-08-13T10:09:33.167941Z","shell.execute_reply":"2025-08-13T10:09:33.173181Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"from transformers import AutoConfig\n\ndef make_model_and_tok():\n    tok=AutoTokenizer.from_pretrained(MODEL_NAME,use_fast=True)\n    config=AutoConfig.from_pretrained(\n        MODEL_NAME,\n        num_labels=2,\n        id2label={0:\"FAKE\",1:\"REAL\"},\n        label2id={\"FAKE\":0,\"REAL\":1},\n        dropout=DROPOUT,\n        attention_dropout=ATTN_DROPOUT,\n    )\n    model=AutoModelForSequenceClassification.from_pretrained(MODEL_NAME,config=config)\n    return model,tok\n\ndef class_weights_from_labels(y:np.ndarray)->torch.Tensor:\n    cw=compute_class_weight(class_weight=\"balanced\",classes=np.array([0,1]),y=y)\n    return torch.tensor(cw,dtype=torch.float)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T10:11:23.242892Z","iopub.execute_input":"2025-08-13T10:11:23.243667Z","iopub.status.idle":"2025-08-13T10:11:23.248923Z","shell.execute_reply.started":"2025-08-13T10:11:23.243640Z","shell.execute_reply":"2025-08-13T10:11:23.248364Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def run_domain_transfer(train_domain_df: pd.DataFrame, test_domain_df: pd.DataFrame, tag: str):\n    \n\n    print(f\"\\n======== Experiment: {tag} ========\")\n    print(f\"Train domain: {train_domain_df['domain'].iloc[0]} | Test domain: {test_domain_df['domain'].iloc[0]}\")\n    print(\"Train size (pre-split):\", len(train_domain_df), \"| Test (zero-shot) size:\", len(test_domain_df))\n\n    # In-domain split: create a train/val/test (holdout) from the training domain\n    # First hold out TEST_FRAC for in-domain testing\n    train_pool, in_domain_test = train_test_split(\n        train_domain_df, test_size=TEST_FRAC, random_state=SEED, stratify=train_domain_df[\"label\"]\n    )\n    # Then take a small validation from the remaining pool\n    train_df, val_df = train_test_split(\n        train_pool, test_size=VAL_FRAC, random_state=SEED, stratify=train_pool[\"label\"]\n    )\n\n    # Safety checks: no title overlap\n    assert set(train_df[\"title\"]).isdisjoint(val_df[\"title\"])\n    assert set(train_df[\"title\"]).isdisjoint(in_domain_test[\"title\"])\n    assert set(val_df[\"title\"]).isdisjoint(in_domain_test[\"title\"])\n\n    # Build tokenizer & datasets\n    model, tok = make_model_and_tok()\n    train_ds = to_hf_dataset(train_df, tok, MAX_LEN)\n    val_ds   = to_hf_dataset(val_df, tok, MAX_LEN)\n    ind_test_ds = to_hf_dataset(in_domain_test, tok, MAX_LEN)\n    xdomain_test_ds = to_hf_dataset(test_domain_df, tok, MAX_LEN)\n\n    # Class weights from TRAIN ONLY\n    class_weights = class_weights_from_labels(train_df[\"label\"].values)\n\n    # Training args\n    out_dir = os.path.join(OUTPUT_DIR, tag)\n    os.makedirs(out_dir, exist_ok=True)\n\n    args = TrainingArguments(\n        output_dir=out_dir,\n        evaluation_strategy=\"epoch\",\n        logging_strategy=\"epoch\",\n        save_strategy=\"epoch\",\n        save_total_limit=2,\n        learning_rate=LR,\n        per_device_train_batch_size=BATCH_TRAIN,\n        per_device_eval_batch_size=BATCH_EVAL,\n        num_train_epochs=EPOCHS,\n        weight_decay=WEIGHT_DECAY,\n        warmup_ratio=WARMUP_RATIO,\n        max_grad_norm=1.0,\n        fp16=torch.cuda.is_available(),\n        load_best_model_at_end=True,\n        metric_for_best_model=\"f1\",\n        report_to=\"none\",\n        logging_steps=50,\n        seed=SEED,\n        dataloader_num_workers=2,\n    )\n\n    trainer = WeightedCELossTrainer(\n        model=model,\n        args=args,\n        train_dataset=train_ds,\n        eval_dataset=val_ds,\n        tokenizer=tok,\n        compute_metrics=metrics_fn,\n        class_weights=class_weights,\n        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n    )\n\n    # Train\n    trainer.train()\n\n    # Evaluate in-domain holdout\n    in_domain_metrics = trainer.evaluate(ind_test_ds)\n    print(\"\\nIn-domain holdout metrics:\", in_domain_metrics)\n\n    # Zero-shot on the other domain\n    xdomain_metrics = trainer.evaluate(xdomain_test_ds)\n    print(\"\\nZero-shot cross-domain metrics:\", xdomain_metrics)\n\n    # Save\n    trainer.save_model(out_dir)\n    tok.save_pretrained(out_dir)\n    print(\"Saved model to:\", out_dir)\n\n    return {\n        \"in_domain\": in_domain_metrics,\n        \"cross_domain\": xdomain_metrics,\n        \"save_dir\": out_dir\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T10:09:39.477898Z","iopub.execute_input":"2025-08-13T10:09:39.478217Z","iopub.status.idle":"2025-08-13T10:09:39.488611Z","shell.execute_reply.started":"2025-08-13T10:09:39.478194Z","shell.execute_reply":"2025-08-13T10:09:39.487712Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"pol = load_domain(POLITIFACT_CSV, \"politifact\")\ngossip = load_domain(GOSSIPCOP_CSV, \"gossipcop\")\n\nprint(\"PolitiFact size:\", len(pol), \"| GossipCop size:\", len(gossip))\nprint(\"PolitiFact label balance:\\n\", pol[\"label\"].value_counts(normalize=True))\nprint(\"GossipCop  label balance:\\n\", gossip[\"label\"].value_counts(normalize=True))\n\n# Run A) Train on PolitiFact -> Test on GossipCop\nres_A = run_domain_transfer(train_domain_df=pol, test_domain_df=gossip, tag=\"train_POL_test_GOSSIP\")\n\n# Run B) Train on GossipCop -> Test on PolitiFact\nres_B = run_domain_transfer(train_domain_df=gossip, test_domain_df=pol, tag=\"train_GOSSIP_test_POL\")\n\nprint(\"\\n==== Summary ====\")\nprint(\"Train POL -> Test GOSSIP:\", {k: {m: round(v, 4) for m, v in d.items() if isinstance(v, (int, float))} for k, d in res_A.items() if isinstance(d, dict)})\nprint(\"Train GOSSIP -> Test POL:\", {k: {m: round(v, 4) for m, v in d.items() if isinstance(v, (int, float))} for k, d in res_B.items() if isinstance(d, dict)})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T10:12:34.138289Z","iopub.execute_input":"2025-08-13T10:12:34.139098Z","iopub.status.idle":"2025-08-13T10:26:21.972019Z","shell.execute_reply.started":"2025-08-13T10:12:34.139073Z","shell.execute_reply":"2025-08-13T10:26:21.971247Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"PolitiFact size: 983 | GossipCop size: 20743\nPolitiFact label balance:\n label\n1    0.566633\n0    0.433367\nName: proportion, dtype: float64\nGossipCop  label balance:\n label\n1    0.769754\n0    0.230246\nName: proportion, dtype: float64\n\n======== Experiment: train_POL_test_GOSSIP ========\nTrain domain: politifact | Test domain: gossipcop\nTrain size (pre-split): 983 | Test (zero-shot) size: 20743\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Tokenizing:   0%|          | 0/707 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51e4997ba34843ab92d772ac5eb4597f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing:   0%|          | 0/79 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70048d0d4b55450bbe27fcb77a47d0b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing:   0%|          | 0/197 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed63d6cc8d10450987bbef75a931c83c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing:   0%|          | 0/20743 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee997839d4684a00a64dafccf304e9f5"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='96' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [96/96 00:53, Epoch 8/8]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.681700</td>\n      <td>0.640344</td>\n      <td>0.848101</td>\n      <td>0.863636</td>\n      <td>0.883721</td>\n      <td>0.844444</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.604400</td>\n      <td>0.526288</td>\n      <td>0.835443</td>\n      <td>0.850575</td>\n      <td>0.880952</td>\n      <td>0.822222</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.464500</td>\n      <td>0.428243</td>\n      <td>0.860759</td>\n      <td>0.881720</td>\n      <td>0.854167</td>\n      <td>0.911111</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.351800</td>\n      <td>0.386445</td>\n      <td>0.873418</td>\n      <td>0.888889</td>\n      <td>0.888889</td>\n      <td>0.888889</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.300900</td>\n      <td>0.375675</td>\n      <td>0.873418</td>\n      <td>0.891304</td>\n      <td>0.872340</td>\n      <td>0.911111</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.285500</td>\n      <td>0.368152</td>\n      <td>0.873418</td>\n      <td>0.888889</td>\n      <td>0.888889</td>\n      <td>0.888889</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.264300</td>\n      <td>0.362421</td>\n      <td>0.886076</td>\n      <td>0.901099</td>\n      <td>0.891304</td>\n      <td>0.911111</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.245800</td>\n      <td>0.362050</td>\n      <td>0.886076</td>\n      <td>0.901099</td>\n      <td>0.891304</td>\n      <td>0.911111</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='165' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2/2 00:46]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"\nIn-domain holdout metrics: {'eval_loss': 0.4003881514072418, 'eval_accuracy': 0.8375634517766497, 'eval_f1': 0.864406779661017, 'eval_precision': 0.8225806451612904, 'eval_recall': 0.9107142857142857, 'eval_runtime': 0.6147, 'eval_samples_per_second': 320.478, 'eval_steps_per_second': 3.254, 'epoch': 8.0}\n\nZero-shot cross-domain metrics: {'eval_loss': 1.3119348287582397, 'eval_accuracy': 0.36474955406643206, 'eval_f1': 0.35429019454108884, 'eval_precision': 0.8141891891891891, 'eval_recall': 0.226404459197094, 'eval_runtime': 46.0358, 'eval_samples_per_second': 450.585, 'eval_steps_per_second': 3.541, 'epoch': 8.0}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Saved model to: /kaggle/working/domain_transfer_distilbert/train_POL_test_GOSSIP\n\n======== Experiment: train_GOSSIP_test_POL ========\nTrain domain: gossipcop | Test domain: politifact\nTrain size (pre-split): 20743 | Test (zero-shot) size: 983\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Tokenizing:   0%|          | 0/14934 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7e648e7f2734adbbfde05daf9944fc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing:   0%|          | 0/1660 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"064ff4c18ad64c5c92496377a20d3c79"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing:   0%|          | 0/4149 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c692bba433e4b70b2313af3c8b5943d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing:   0%|          | 0/983 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd8ea51fa01145978c60c0c930e2fd21"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1638' max='1872' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1638/1872 11:44 < 01:40, 2.32 it/s, Epoch 7/8]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Precision</th>\n      <th>Recall</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.595600</td>\n      <td>0.474482</td>\n      <td>0.760241</td>\n      <td>0.827107</td>\n      <td>0.929688</td>\n      <td>0.744914</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.466300</td>\n      <td>0.428486</td>\n      <td>0.814458</td>\n      <td>0.871560</td>\n      <td>0.933036</td>\n      <td>0.817684</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.419400</td>\n      <td>0.424480</td>\n      <td>0.799398</td>\n      <td>0.858479</td>\n      <td>0.939535</td>\n      <td>0.790297</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.387800</td>\n      <td>0.418133</td>\n      <td>0.832530</td>\n      <td>0.886159</td>\n      <td>0.929553</td>\n      <td>0.846635</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.357600</td>\n      <td>0.438533</td>\n      <td>0.837952</td>\n      <td>0.892011</td>\n      <td>0.915911</td>\n      <td>0.869327</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.334400</td>\n      <td>0.432910</td>\n      <td>0.831928</td>\n      <td>0.886815</td>\n      <td>0.920809</td>\n      <td>0.855243</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.313600</td>\n      <td>0.439361</td>\n      <td>0.831325</td>\n      <td>0.885901</td>\n      <td>0.924320</td>\n      <td>0.850548</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='41' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [33/33 00:11]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"\nIn-domain holdout metrics: {'eval_loss': 0.43598473072052, 'eval_accuracy': 0.8353820197637986, 'eval_f1': 0.8897853800225917, 'eval_precision': 0.9180819180819181, 'eval_recall': 0.8631809643080777, 'eval_runtime': 9.2592, 'eval_samples_per_second': 448.097, 'eval_steps_per_second': 3.564, 'epoch': 7.0}\n\nZero-shot cross-domain metrics: {'eval_loss': 1.055993676185608, 'eval_accuracy': 0.3957273652085453, 'eval_f1': 0.35010940919037203, 'eval_precision': 0.4481792717086835, 'eval_recall': 0.2872531418312388, 'eval_runtime': 2.3366, 'eval_samples_per_second': 420.693, 'eval_steps_per_second': 3.424, 'epoch': 7.0}\nSaved model to: /kaggle/working/domain_transfer_distilbert/train_GOSSIP_test_POL\n\n==== Summary ====\nTrain POL -> Test GOSSIP: {'in_domain': {'eval_loss': 0.4004, 'eval_accuracy': 0.8376, 'eval_f1': 0.8644, 'eval_precision': 0.8226, 'eval_recall': 0.9107, 'eval_runtime': 0.6147, 'eval_samples_per_second': 320.478, 'eval_steps_per_second': 3.254, 'epoch': 8.0}, 'cross_domain': {'eval_loss': 1.3119, 'eval_accuracy': 0.3647, 'eval_f1': 0.3543, 'eval_precision': 0.8142, 'eval_recall': 0.2264, 'eval_runtime': 46.0358, 'eval_samples_per_second': 450.585, 'eval_steps_per_second': 3.541, 'epoch': 8.0}}\nTrain GOSSIP -> Test POL: {'in_domain': {'eval_loss': 0.436, 'eval_accuracy': 0.8354, 'eval_f1': 0.8898, 'eval_precision': 0.9181, 'eval_recall': 0.8632, 'eval_runtime': 9.2592, 'eval_samples_per_second': 448.097, 'eval_steps_per_second': 3.564, 'epoch': 7.0}, 'cross_domain': {'eval_loss': 1.056, 'eval_accuracy': 0.3957, 'eval_f1': 0.3501, 'eval_precision': 0.4482, 'eval_recall': 0.2873, 'eval_runtime': 2.3366, 'eval_samples_per_second': 420.693, 'eval_steps_per_second': 3.424, 'epoch': 7.0}}\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import shutil\n\nshutil.make_archive(\"/kaggle/working/model_POL\", 'zip', \"/kaggle/working/domain_transfer_distilbert/train_POL_test_GOSSIP\")\nshutil.make_archive(\"/kaggle/working/model_GOSSIP\", 'zip', \"/kaggle/working/domain_transfer_distilbert/train_GOSSIP_test_POL\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-13T10:28:03.772693Z","iopub.execute_input":"2025-08-13T10:28:03.773406Z","execution_failed":"2025-08-13T11:56:46.003Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}